<!doctype html><html lang=zh dir=ltr>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content>
<meta name=theme-color content="#FFFFFF">
<meta name=color-scheme content="light dark"><meta property="og:title" content="文章">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://blog.llaoj.cn/posts/">
<title>文章 | 老J的博客</title>
<link rel=manifest href=/manifest.json>
<link rel=icon href=/favicon.png type=image/x-icon>
<link rel=stylesheet href=/book.min.18b5d651e266e5e9cfc7455e2e50eb1b74a62aee16cf204b69de1d9e695276f7.css integrity="sha256-GLXWUeJm5enPx0VeLlDrG3SmKu4WzyBLad4dnmlSdvc=" crossorigin=anonymous>
<script defer src=/flexsearch.min.js></script>
<script defer src=/zh.search.min.11c819f035f42e5353e942007ed2c14ea2ed8dae58e2791b4bd2686764cb892d.js integrity="sha256-EcgZ8DX0LlNT6UIAftLBTqLtja5Y4nkbS9JoZ2TLiS0=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script>
<link rel=alternate type=application/rss+xml href=https://blog.llaoj.cn/posts/index.xml title=老J的博客>
<script>var _hmt=_hmt||[];(function(){var a=document.createElement("script"),b;a.src="https://hm.baidu.com/hm.js?7f5ad4632a1c2df3cd8e1199a7aaf48a",b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script>
</head>
<body dir=ltr>
<input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control>
<main class="container flex">
<aside class=book-menu>
<div class=book-menu-content>
<nav>
<h2 class=book-brand>
<a class="flex align-center" href=/><img src=/j.png alt=Logo><span>老J的博客</span>
</a>
</h2>
<div class=book-search>
<input type=text id=book-search-input placeholder=搜索 aria-label=搜索 maxlength=64 data-hotkeys=s/>
<div class="book-search-spinner hidden"></div>
<ul id=book-search-results></ul>
</div>
<ul>
<li>
<a href=/posts/>
文章
</a>
</li>
</ul>
<ul>
<li>
<a href=/docs/oauth2nsso/>OAuth2&SSO</a>
<ul>
<li>
<a href=/docs/oauth2nsso/configuration/>配置</a>
</li>
<li>
<a href=/docs/oauth2nsso/apis/>API列表</a>
</li>
<li>
<a href=/docs/oauth2nsso/deploy/>部署</a>
</li>
<li>
<a href=/docs/oauth2nsso/note/>说明</a>
</li>
<li>
<a href=/docs/oauth2nsso/demo/>示例</a>
</li>
<li>
<a href=/docs/oauth2nsso/for-client/>接入指引</a>
</li>
</ul>
</li>
<li>
<a href=/docs/about/>关于</a>
<ul>
</ul>
</li>
</ul>
<ul>
<li>
<a href=https://www.cncf.io/ target=_blank rel=noopener>
CNCF
</a>
</li>
<li>
<a href=https://ebpf.io/ target=_blank rel=noopener>
eBPF
</a>
</li>
</ul>
<div class=book-menu-after>
<a href=https://www.rutron.net/ target=_blank>@如创科技</a><br>提供云计算支持
</div>
</nav>
<script>(function(){var a=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>
</div>
</aside>
<div class=book-page>
<header class=book-header>
<div class="flex align-center justify-between">
<label for=menu-control>
<img src=/svg/menu.svg class=book-icon alt=Menu>
</label>
<strong>文章</strong>
<label for=toc-control>
<img src=/svg/toc.svg class=book-icon alt="Table of Contents">
</label>
</div>
<aside class="hidden clearfix">
<nav>
<ul>
<li class=book-section-flat>
<strong>Categories</strong>
<ul>
<li class="flex justify-between">
<a href=/categories/technology/>technology</a>
<span>32</span>
</li>
</ul>
</li>
<li class=book-section-flat>
<strong>Tags</strong>
<ul>
<li class="flex justify-between">
<a href=/tags/docker/>docker</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/oracle/>oracle</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/fluentd/>fluentd</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/envoy/>envoy</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/rsync/>rsync</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/etcd/>etcd</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/istio/>istio</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/metallb/>metallb</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubernetes/>kubernetes</a>
<span>17</span>
</li>
<li class="flex justify-between">
<a href=/tags/cgroups/>cgroups</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/apisix/>apisix</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/grafana-mimir/>grafana mimir</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/prometheus/>prometheus</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/golang/>golang</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/harbor/>harbor</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/bcc/>bcc</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/ebpf/>ebpf</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubectl/>kubectl</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubelet/>kubelet</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/linux/>linux</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/nfs/>nfs</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/ldap/>ldap</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubespray/>kubespray</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/pod/>pod</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/ppt/>ppt</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/backup/>backup</a>
<span>1</span>
</li>
</ul>
</li>
</ul>
</nav>
</aside>
</header>
<article class="markdown book-post">
<h2>
<a href=/posts/2210/docker-oracle-xe-11g/>使用docker运行orcale xe 11g</a>
</h2>
<h5>2022-10-18</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/docker/>docker</a>,
<a href=/tags/oracle/>oracle</a>
</div>
<p>注意: 根据自己实际情况, 替换下面名利中的&lt;var>变量.
启动orcale xe 11g容器 # Oracle Database XE是人人都可免费使用的 Oracle 数据库. Oracle Database XE 支持最高:
最多 12 GB 的用户磁盘数据 最大 2 GB 的数据库 RAM 最多 2 个 CPU 线程 产品介绍地址: https://www.oracle.com/cn/database/technologies/appdev/xe.html
Oracle Database XE支持容器化部署, 镜像项目地址(这里面也有详细使用文档): https://hub.docker.com/r/oracleinanutshell/oracle-xe-11g
docker run -d \ --name=oracle-xe-11g \ --restart=always \ -p 31521:1521 \ -p 38080:8080 \ -v /data/oracle_data:/opt/oracle/oracle_data:rw \ oracleinanutshell/oracle-xe-11g 该镜像的默认登录信息是:
hostname: localhost port: 31521 sid: xe username: system 或者 sys password: oracle 使用了主机的/data/oracle_data目录作为数据持久化目录.
<a href=/posts/2210/docker-oracle-xe-11g/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2209/fluentd-kubernetes-daemonset/>使用fluentd收集kubernetes日志并推送到ES</a>
</h2>
<h5>2022-9-20</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/fluentd/>fluentd</a>
</div>
<p>这篇文章使用fluentd官方提供的kubernetes部署方案daemonset来部署日志收集, 参考项目地址:
https://github.com/fluent/fluentd-kubernetes-daemonset 本文使用的kubernetes版本为: 1.22.8
使用fluentd镜像为: fluent/fluentd-kubernetes-daemonset:v1.15.2-debian-elasticsearch7-1.0
请注意下文配置中&lt;var>标记, 需要根据需求自行替换.
创建命名空间 # 本项目所有的资源创建在logging下, 先创建它:
NAMESPACE=logging kubectl create ns $NAMESPACE 先创建服务账号 # 创建服务账号并赋予集群查看的权限, 使用下面的命令:
kubectl -n $NAMESPACE create -f - &lt;&lt;EOF apiVersion: v1 kind: ServiceAccount metadata: name: fluentd EOF 创建绑定关系:
kubectl create -f - &lt;&lt;EOF kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: fluentd roleRef: kind: ClusterRole name: view apiGroup: rbac.authorization.k8s.io subjects: - kind: ServiceAccount name: fluentd namespace: ${NAMESPACE} EOF 创建配置文件 # 配置文件使用configmap挂在在容器内, 覆盖容器内现有的配置文件.
<a href=/posts/2209/fluentd-kubernetes-daemonset/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2209/envoy-usage/>Envoy的静态配置使用方法</a>
</h2>
<h5>2022-9-15</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/envoy/>envoy</a>
</div>
<p>Envoy静态配置 # L4转发 # 下面的例子是配置4层转发, 将443端口的流量都代理到www.example.com对应的后端的443端口上, 如下:
static_resources:listeners:- name:listener_0address:socket_address:protocol:TCPaddress:0.0.0.0port_value:443filter_chains:- filters:- name:envoy.filters.network.tcp_proxytyped_config:"@type": type.googleapis.com/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxystat_prefix:tcp_443cluster:cluster_0clusters:- name:cluster_0type:LOGICAL_DNSdns_lookup_family:V4_ONLYload_assignment:cluster_name:cluster_0endpoints:- lb_endpoints:- endpoint:address:socket_address:address:www.example.comport_value:443启动Envoy # 将创建的静态配置文件envoy-custom.yaml映射到容器内部, 启动:
docker run -d --name=envoy --restart=always \ -p 443:443 -v /root/envoy-custom.yaml:/etc/envoy/envoy.yaml \ envoyproxy/envoy:v1.22.2
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2208/rsync-usage/>使用rsync在主机之间同步目录</a>
</h2>
<h5>2022-8-30</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/rsync/>rsync</a>
</div>
<p>rsync安装 # 在传输双方的服务器上都安装rsync软件. 如果服务器上有rsync可以跳过.
先检查有没有安装rsync:
rsync -h 如果没有安装, 使用下面的命令安装:
# Debian sudo apt-get install rsync # Red Hat sudo yum install rsync # Arch Linux sudo pacman -S rsync 启动rsync守护进程 # rsync使用最多的是ssh模式. 在现代的公司中, 出于安全的原因, 很多ssh是被禁止使用的. 所以, 我们可以使用rsync的守护进程模式. 一起看看怎么用吧.
rsync守护进程部署在传输双方(发送方或者接受方)的任何一端都可以的.
下面的配置和命令中, 我以发送方(10.138.228.201)和接收方(10.206.38.30)为例.
我选择接收方, 先部署配置文件. 配置文件地址: /etc/rsyncd.conf. 配置文件 官方参考手册
以下是一个参考的配置, 每一项配置我都增加了备注说明:
# 指定rsync以什么用户/组传输文件 # 默认nobody,如果使用了系统不存在的用户和组 # 需要先手动创建用户和组 # 它会是生成的文件所属的用户和组 # 也可以把它们配置到模块中 uid = root gid = root # 选择yes可以在操作模块时chroot到同步目录中 # 优势是面对安全威胁能提供额外保护 # 缺点是使用chroot需要root权限, # 以及在传输符号连接或保存用户名/组时会有些问题 use chroot = no # 指定监听端口 # 默认873 port = 873 # 最大连接数 max connections = 200 # 超时时间 timeout = 600 # 进程pid所在的文件 pid file = /var/run/rsyncd.
<a href=/posts/2208/rsync-usage/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2208/kubernetes-etcdctl-usage/>使用etcdctl查看kubernetes存储的内容</a>
</h2>
<h5>2022-8-29</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/etcd/>etcd</a>
</div>
<p>下面这个脚本提供了etcdctl连接etcd所需要的断点、证书相关的信息, 能快速或许并调用命令查看, 这个脚本需要在master节点上执行:
#!/bin/bash ENDPOINTS=$(ps -ef | grep kube-apiserver | grep -P 'etcd-servers=(.*?)\s' -o | awk -F= '{print $2}') CACERT=$(ps -ef | grep kube-apiserver | grep -P 'etcd-cafile=(.*?)\s' -o | awk -F= '{print $2}') CERT=$(ps -ef | grep kube-apiserver | grep -P 'etcd-certfile=(.*?)\s' -o | awk -F= '{print $2}') KEY=$(ps -ef | grep kube-apiserver | grep -P 'etcd-keyfile=(.*?)\s' -o | awk -F= '{print $2}') alias etcdctl='ETCDCTL_API=3 etcdctl --endpoints=${ENDPOINTS} --cacert=${CACERT} --key=${KEY} --cert=${CERT} -w=json' 好了下面可以直接使用etcdctl命令了, 比如:
<a href=/posts/2208/kubernetes-etcdctl-usage/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2208/metallb-l2-usage/>MetalLB二层模式使用指南</a>
</h2>
<h5>2022-8-8</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/metallb/>metallb</a>
</div>
<p>MetalLB概念安装配置和使用请查看
测试组件的版本情况 # kubernetes: v1.22.8 metellb: v0.10.3 nginx: latest 创建测试应用 # 创建一个nginx服务和service资源:
kubectl -n without-istio create deploy nginx --image=nginx 测试分配IP # 创建loadbalancer类型的service:
kubectl -n without-istio create service loadbalancer nginx --tcp=80:80 查看该service详细配置:
apiVersion:v1kind:Servicemetadata:labels:app:nginxnamespace:without-istioname:nginx...spec:allocateLoadBalancerNodePorts:trueclusterIP:10.233.15.89clusterIPs:- 10.233.15.89externalTrafficPolicy:ClusterinternalTrafficPolicy:ClusteripFamilies:- IPv4ipFamilyPolicy:SingleStackports:- name:80-80nodePort:30662port:80protocol:TCPtargetPort:80selector:app:nginxsessionAffinity:Nonetype:LoadBalancerstatus:loadBalancer:ingress:- ip:10.206.65.234可以发现external-ip已经完成分配.
在同一个局域网内, 使用curl命令测试联通情况:
可以看到, 是可以正常访问的.
手动指定地址池 # 默认, metallb会从所有的可用地址池中分配IP, 除非我们关闭某一个地址池的自动分配auto-assign: false.
metallb v0.12之前都是用configmap进行配置, 而不是用CRD. 这里是 配置相关文档.
下面我们让集群中有两个地址池, 其中一个关闭自动分配. 修改metallb的配置文件, 增加一个address-pools(expensive), 地址范围10.206.65.224-10.206.65.233, 如下:
kubectl -n metallb-system edit cm config 可以看到目前有两个地址池, 同时配置auto-assign: false来关闭对expensive地址池的自动分配.
<a href=/posts/2208/metallb-l2-usage/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2208/istio-with-nginx-reserve-proxy/>在istio service mesh中使用nginx反向代理</a>
</h2>
<h5>2022-8-8</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/istio/>istio</a>
</div>
<p>nginx反向代理的请求, 和我们直接请求有一定的区别, 比如:
http version # nginx proxy 发出的反向代理请求的http version默认是: 1.0, 但是istio支持1.1 & 2.0, 所以如果不增加http版本限制的话istio就无法进行报文解析, 也就无法应用istio-proxy(sidecar)L7层代理策略, 我们知道istio流量治理是基于L7层的.
http header: Host # 有时候nginx发出的代理请求的http header中host的值, 不能保证是上游服务的host name. 在这种情况下, 是没办法匹配上游服务在istio-proxy中的L7流量治理的配置.
怎么解决? # 所以, 需要在nginx代理配置处增加两项配置:
... location / { proxy_http_version 1.1; &lt;- proxy_set_header Host &lt;upstream-host>; &lt;- proxy_pass http://&lt;upstream-host>:8080; } ... 即可.
参考 # nginx官方文档proxy_http_version介绍 nginx官方文档proxy_set_header介绍
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2207/fluentd-es-config/>Fluentd配置文件最佳实践</a>
</h2>
<h5>2022-7-31</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/kubernetes/>kubernetes</a>,
<a href=/tags/fluentd/>fluentd</a>
</div>
<p>Fluentd负责Kubernetes中容器日志的收集工作, 以Daemonset形式运行在每一个节点上. 下面这个配置是在多个生产集群使用的配置, 经过多次调优的. 有一些关键的配置增加了配置解释说明. 目前使用问题不大. 持续更新配置中&mldr;
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2207/kubernetes-requirement/>Kubernetes 服务器配置和规划建设要求</a>
</h2>
<h5>2022-7-16</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/kubernetes/>kubernetes</a>
</div>
<p>新建集群的第一步就是要规划服务器、网络、操作系统等等, 下面就结合我平时的工作经验总结下相关的要求, 内容根据日常工作持续补充完善:
服务器配置 # kubernetes 集群分为控制节点和数据节点, 它们对于配置的要求有所不同:
控制面 # 节点规模 Master规格 1~5个节点 4核 8Gi（不建议2核 4Gi） 6~20个节点 4核 16Gi 21~100个节点 8核 32Gi 100~200个节点 16核 64Gi 系统盘40+Gi，用于储存 etcd 信息及相关配置文件等
数据面 # 规格：CPU >= 4核, 内存 >= 8Gi 确定整个集群的日常使用的总核数以及可用度的容忍度 例如：集群总的核数有160核, 可以容忍10%的错误. 那么最小选择10台16核VM, 并且高峰运行的负荷不要超过 160*90%=144核. 如果容忍度是20%, 那么最小选择5台32核VM, 并且高峰运行的负荷不要超过160*80%=128核. 这样就算有一台VM出现故障, 剩余VM仍可以支持现有业务正常运行. 确定 CPU:Memory 比例.
<a href=/posts/2207/kubernetes-requirement/>...</a>
</p>
</article>
<article class="markdown book-post">
<h2>
<a href=/posts/2205/metalb/>MetalLB概念安装配置和使用</a>
</h2>
<h5>2022-5-30</h5>
<div>
<a href=/categories/technology/>technology</a>
</div>
<div>
<a href=/tags/metallb/>metallb</a>
</div>
<p>官方文档
为什么使用? # Kubernetes没有提供适用于裸金属集群的网络负载均衡器实现, 也就是LoadBalancer类型的Service. Kubernetes 附带的网络负载均衡器的实现都是调用各种 IaaS 平台（GCP、AWS、Azure ……）的胶水代码。 如果您没有在受支持的 IaaS 平台（GCP、AWS、Azure&mldr;）上运行，LoadBalancers 在创建时将一直保持在pending状态。
裸金属集群的运维人员只剩下两个方式来将用户流量引入集群内: NodePort和externalIPs. 这两种在生产环境使用有很大的缺点, 这样, 裸金属集群也就成了 Kubernetes 生态中的第二类选择, 并不是首选.
MetalLB 的目的是实现一个网络负载均衡器来与标准的网络设备集成, 这样这些外部服务就能尽可能的正常工作了.
要求 # MetalLB 要求如下:
一个 Kubernetes 集群, Kubernetes 版本 1.13.0+, 没有网络负载均衡器功能. 可以与 MetalLB 共存的集群网络配置。 一些供 MetalLB 分发的 IPv4 地址。 当使用 BGP 操作模式时，您将需要一台或多台能够发布 BGP 的路由器。 使用 L2 操作模式时，节点之间必须允许 7946 端口（TCP 和 UDP，可配置其他端口）上的流量，这是 hashicorp/memberlist 的要求。 功能 # MetalLB 是作为 Kubernetes 中的一个组件, 提供了一个网络负载均衡器的实现.
<a href=/posts/2205/metalb/>...</a>
</p>
</article>
<ul class="pagination pagination-default">
<li class="page-item disabled">
<a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;&#171;</span></a>
</li>
<li class="page-item disabled">
<a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;</span></a>
</li>
<li class="page-item active">
<a aria-current=page aria-label="Page 1" class=page-link role=button>1</a>
</li>
<li class=page-item>
<a href=/posts/page/2/ aria-label="Page 2" class=page-link role=button>2</a>
</li>
<li class=page-item>
<a href=/posts/page/3/ aria-label="Page 3" class=page-link role=button>3</a>
</li>
<li class=page-item>
<a href=/posts/page/4/ aria-label="Page 4" class=page-link role=button>4</a>
</li>
<li class=page-item>
<a href=/posts/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a>
</li>
<li class=page-item>
<a href=/posts/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a>
</li>
</ul>
<footer class=book-footer>
<div class="flex flex-wrap justify-between">
</div>
<script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){if(window.getSelection().toString())return;a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>
</footer>
<label for=menu-control class="hidden book-menu-overlay"></label>
</div>
<aside class=book-toc>
<div class=book-toc-content>
<nav>
<ul>
<li class=book-section-flat>
<strong>Categories</strong>
<ul>
<li class="flex justify-between">
<a href=/categories/technology/>technology</a>
<span>32</span>
</li>
</ul>
</li>
<li class=book-section-flat>
<strong>Tags</strong>
<ul>
<li class="flex justify-between">
<a href=/tags/docker/>docker</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/oracle/>oracle</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/fluentd/>fluentd</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/envoy/>envoy</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/rsync/>rsync</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/etcd/>etcd</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/istio/>istio</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/metallb/>metallb</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubernetes/>kubernetes</a>
<span>17</span>
</li>
<li class="flex justify-between">
<a href=/tags/cgroups/>cgroups</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/apisix/>apisix</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/grafana-mimir/>grafana mimir</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/prometheus/>prometheus</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/golang/>golang</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/harbor/>harbor</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/bcc/>bcc</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/ebpf/>ebpf</a>
<span>3</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubectl/>kubectl</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubelet/>kubelet</a>
<span>2</span>
</li>
<li class="flex justify-between">
<a href=/tags/linux/>linux</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/nfs/>nfs</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/ldap/>ldap</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/kubespray/>kubespray</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/pod/>pod</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/ppt/>ppt</a>
<span>1</span>
</li>
<li class="flex justify-between">
<a href=/tags/backup/>backup</a>
<span>1</span>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</aside>
</main>
</body>
</html>